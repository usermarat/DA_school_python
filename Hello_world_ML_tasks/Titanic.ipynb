{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv', index_col='PassengerId')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 11 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Survived  891 non-null    int64  \n",
      " 1   Pclass    891 non-null    int64  \n",
      " 2   Name      891 non-null    object \n",
      " 3   Sex       891 non-null    object \n",
      " 4   Age       714 non-null    float64\n",
      " 5   SibSp     891 non-null    int64  \n",
      " 6   Parch     891 non-null    int64  \n",
      " 7   Ticket    891 non-null    object \n",
      " 8   Fare      891 non-null    float64\n",
      " 9   Cabin     204 non-null    object \n",
      " 10  Embarked  889 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 83.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Icard, Miss. Amelie</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Stone, Mrs. George Nelson (Martha Evelyn)</td>\n",
       "      <td>female</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass                                       Name  \\\n",
       "PassengerId                                                                \n",
       "62                  1       1                        Icard, Miss. Amelie   \n",
       "830                 1       1  Stone, Mrs. George Nelson (Martha Evelyn)   \n",
       "\n",
       "                Sex   Age  SibSp  Parch  Ticket  Fare Cabin Embarked  \n",
       "PassengerId                                                           \n",
       "62           female  38.0      0      0  113572  80.0   B28      NaN  \n",
       "830          female  62.0      0      0  113572  80.0   B28      NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['Embarked'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>168.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>168.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.553571</td>\n",
       "      <td>1.886905</td>\n",
       "      <td>30.814769</td>\n",
       "      <td>0.386905</td>\n",
       "      <td>0.363095</td>\n",
       "      <td>59.954144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.498608</td>\n",
       "      <td>0.944100</td>\n",
       "      <td>15.434860</td>\n",
       "      <td>0.557213</td>\n",
       "      <td>0.660481</td>\n",
       "      <td>83.912994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.697950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>78.500025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Survived      Pclass         Age       SibSp       Parch        Fare\n",
       "count  168.000000  168.000000  130.000000  168.000000  168.000000  168.000000\n",
       "mean     0.553571    1.886905   30.814769    0.386905    0.363095   59.954144\n",
       "std      0.498608    0.944100   15.434860    0.557213    0.660481   83.912994\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    4.012500\n",
       "25%      0.000000    1.000000   21.250000    0.000000    0.000000   13.697950\n",
       "50%      1.000000    1.000000   29.000000    0.000000    0.000000   29.700000\n",
       "75%      1.000000    3.000000   40.000000    1.000000    1.000000   78.500025\n",
       "max      1.000000    3.000000   71.000000    2.000000    3.000000  512.329200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.query('Embarked == \"C\"').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Embarked'] = data['Embarked'].fillna('C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      577\n",
       "female    314\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    549\n",
       "1    342\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    644\n",
       "C    168\n",
       "Q     77\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Embarked.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Survived      Pclass         Age       SibSp       Parch        Fare\n",
       "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'Survived'}>,\n",
       "        <AxesSubplot:title={'center':'Pclass'}>],\n",
       "       [<AxesSubplot:title={'center':'Age'}>,\n",
       "        <AxesSubplot:title={'center':'SibSp'}>],\n",
       "       [<AxesSubplot:title={'center':'Parch'}>,\n",
       "        <AxesSubplot:title={'center':'Fare'}>]], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.hist(bins='auto', figsize=(20,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.33848104],\n",
       "       [-0.33848104,  1.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(data['Pclass'].values, data['Survived'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Survived'].values\n",
    "num = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "cat = ['Pclass', 'Sex', 'Embarked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipe = Pipeline([('imputer', SimpleImputer(strategy=\"mean\")),\n",
    "                     ('scaler', StandardScaler())])\n",
    "\n",
    "prep_pipe = ColumnTransformer([('num', num_pipe, num),\n",
    "                               ('cat', OneHotEncoder(), cat)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = prep_pipe.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pipe = Pipeline([('preparation', prep_pipe),\n",
    "                     ('clf', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7912457912457912 {'clf': LogisticRegression()}\n",
      "0.8271604938271605 {'clf': SVC()}\n",
      "0.7643097643097643 {'clf': DecisionTreeClassifier()}\n",
      "0.7968574635241302 {'clf': RandomForestClassifier()}\n",
      "0.8092031425364757 {'clf': GradientBoostingClassifier()}\n"
     ]
    }
   ],
   "source": [
    "grid_clf = GridSearchCV(clf_pipe, {'clf': [LogisticRegression(),\n",
    "                                           SVC(),\n",
    "                                           DecisionTreeClassifier(), \n",
    "                                           RandomForestClassifier(), \n",
    "                                           GradientBoostingClassifier()]}, \n",
    "                        scoring='accuracy', cv=StratifiedKFold(3))\n",
    "grid_clf.fit(data, y)\n",
    "\n",
    "cvres = grid_clf.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 335, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 268, in _dense_fit\n",
      "    self._probB, self.fit_status_ = libsvm.fit(\n",
      "  File \"sklearn\\svm\\_libsvm.pyx\", line 191, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7912457912457912 {'clf': LogisticRegression()}\n",
      "0.8271604938271605 {'clf': SVC()}\n",
      "0.7643097643097643 {'clf': DecisionTreeClassifier()}\n",
      "0.7968574635241302 {'clf': RandomForestClassifier()}\n",
      "0.8092031425364757 {'clf': GradientBoostingClassifier()}\n"
     ]
    }
   ],
   "source": [
    "svc_pipe = Pipeline([('preparation', prep_pipe),\n",
    "                     ('clf', SVC(random_state=42))])\n",
    "\n",
    "param = {'preparation__num__imputer__strategy': ['mean', 'median', 'most_frequent'],\n",
    "         'preparation__num__scaler': [MinMaxScaler(), StandardScaler()],\n",
    "         'clf__C': [0, 1, 10, 50, 100],\n",
    "         'clf__kernel': ['rbf', 'linear', 'poly', 'sigmoid']}\n",
    "\n",
    "grid_svc = GridSearchCV(svc_pipe, param, scoring='accuracy', cv=StratifiedKFold(3))\n",
    "\n",
    "grid_svc.fit(data, y)\n",
    "\n",
    "svc_res = grid_svc.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan {'clf__C': 0, 'clf__kernel': 'rbf', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': MinMaxScaler()}\n",
      "nan {'clf__C': 0, 'clf__kernel': 'rbf', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': StandardScaler()}\n",
      "nan {'clf__C': 0, 'clf__kernel': 'rbf', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': MinMaxScaler()}\n",
      "nan {'clf__C': 0, 'clf__kernel': 'rbf', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': StandardScaler()}\n",
      "nan {'clf__C': 0, 'clf__kernel': 'rbf', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': MinMaxScaler()}\n",
      "nan {'clf__C': 0, 'clf__kernel': 'rbf', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': StandardScaler()}\n",
      "nan {'clf__C': 0, 'clf__kernel': 'linear', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': MinMaxScaler()}\n",
      "nan {'clf__C': 0, 'clf__kernel': 'linear', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': StandardScaler()}\n",
      "nan {'clf__C': 0, 'clf__kernel': 'linear', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': MinMaxScaler()}\n",
      "nan {'clf__C': 0, 'clf__kernel': 'linear', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': StandardScaler()}\n",
      "nan {'clf__C': 0, 'clf__kernel': 'linear', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': MinMaxScaler()}\n",
      "nan {'clf__C': 0, 'clf__kernel': 'linear', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': StandardScaler()}\n",
      "nan {'clf__C': 0, 'clf__kernel': 'poly', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': MinMaxScaler()}\n",
      "nan {'clf__C': 0, 'clf__kernel': 'poly', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': StandardScaler()}\n",
      "nan {'clf__C': 0, 'clf__kernel': 'poly', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': MinMaxScaler()}\n",
      "nan {'clf__C': 0, 'clf__kernel': 'poly', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': StandardScaler()}\n",
      "nan {'clf__C': 0, 'clf__kernel': 'poly', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': MinMaxScaler()}\n",
      "nan {'clf__C': 0, 'clf__kernel': 'poly', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': StandardScaler()}\n",
      "nan {'clf__C': 0, 'clf__kernel': 'sigmoid', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': MinMaxScaler()}\n",
      "nan {'clf__C': 0, 'clf__kernel': 'sigmoid', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': StandardScaler()}\n",
      "nan {'clf__C': 0, 'clf__kernel': 'sigmoid', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': MinMaxScaler()}\n",
      "nan {'clf__C': 0, 'clf__kernel': 'sigmoid', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': StandardScaler()}\n",
      "nan {'clf__C': 0, 'clf__kernel': 'sigmoid', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': MinMaxScaler()}\n",
      "nan {'clf__C': 0, 'clf__kernel': 'sigmoid', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': StandardScaler()}\n",
      "0.8114478114478114 {'clf__C': 1, 'clf__kernel': 'rbf', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.8271604938271605 {'clf__C': 1, 'clf__kernel': 'rbf', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': StandardScaler()}\n",
      "0.8114478114478114 {'clf__C': 1, 'clf__kernel': 'rbf', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.8271604938271605 {'clf__C': 1, 'clf__kernel': 'rbf', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': StandardScaler()}\n",
      "0.8114478114478114 {'clf__C': 1, 'clf__kernel': 'rbf', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.8260381593714928 {'clf__C': 1, 'clf__kernel': 'rbf', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': StandardScaler()}\n",
      "0.7867564534231201 {'clf__C': 1, 'clf__kernel': 'linear', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.7867564534231201 {'clf__C': 1, 'clf__kernel': 'linear', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': StandardScaler()}\n",
      "0.7867564534231201 {'clf__C': 1, 'clf__kernel': 'linear', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.7867564534231201 {'clf__C': 1, 'clf__kernel': 'linear', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': StandardScaler()}\n",
      "0.7867564534231201 {'clf__C': 1, 'clf__kernel': 'linear', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.787878787878788 {'clf__C': 1, 'clf__kernel': 'linear', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': StandardScaler()}\n",
      "0.8114478114478114 {'clf__C': 1, 'clf__kernel': 'poly', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.8249158249158249 {'clf__C': 1, 'clf__kernel': 'poly', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': StandardScaler()}\n",
      "0.8114478114478114 {'clf__C': 1, 'clf__kernel': 'poly', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.8215488215488215 {'clf__C': 1, 'clf__kernel': 'poly', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': StandardScaler()}\n",
      "0.8114478114478114 {'clf__C': 1, 'clf__kernel': 'poly', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.8260381593714926 {'clf__C': 1, 'clf__kernel': 'poly', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': StandardScaler()}\n",
      "0.6262626262626263 {'clf__C': 1, 'clf__kernel': 'sigmoid', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.6857463524130191 {'clf__C': 1, 'clf__kernel': 'sigmoid', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': StandardScaler()}\n",
      "0.6722783389450057 {'clf__C': 1, 'clf__kernel': 'sigmoid', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.68013468013468 {'clf__C': 1, 'clf__kernel': 'sigmoid', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': StandardScaler()}\n",
      "0.6430976430976431 {'clf__C': 1, 'clf__kernel': 'sigmoid', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.6767676767676768 {'clf__C': 1, 'clf__kernel': 'sigmoid', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': StandardScaler()}\n",
      "0.8215488215488215 {'clf__C': 10, 'clf__kernel': 'rbf', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.8080808080808081 {'clf__C': 10, 'clf__kernel': 'rbf', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': StandardScaler()}\n",
      "0.8215488215488215 {'clf__C': 10, 'clf__kernel': 'rbf', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.8103254769921436 {'clf__C': 10, 'clf__kernel': 'rbf', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': StandardScaler()}\n",
      "0.8237934904601572 {'clf__C': 10, 'clf__kernel': 'rbf', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.8103254769921436 {'clf__C': 10, 'clf__kernel': 'rbf', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': StandardScaler()}\n",
      "0.7867564534231201 {'clf__C': 10, 'clf__kernel': 'linear', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.7856341189674523 {'clf__C': 10, 'clf__kernel': 'linear', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': StandardScaler()}\n",
      "0.7867564534231201 {'clf__C': 10, 'clf__kernel': 'linear', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.7867564534231201 {'clf__C': 10, 'clf__kernel': 'linear', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': StandardScaler()}\n",
      "0.787878787878788 {'clf__C': 10, 'clf__kernel': 'linear', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.7867564534231201 {'clf__C': 10, 'clf__kernel': 'linear', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': StandardScaler()}\n",
      "0.8193041526374859 {'clf__C': 10, 'clf__kernel': 'poly', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.8148148148148149 {'clf__C': 10, 'clf__kernel': 'poly', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': StandardScaler()}\n",
      "0.8193041526374859 {'clf__C': 10, 'clf__kernel': 'poly', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.8170594837261503 {'clf__C': 10, 'clf__kernel': 'poly', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': StandardScaler()}\n",
      "0.8193041526374859 {'clf__C': 10, 'clf__kernel': 'poly', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.8103254769921436 {'clf__C': 10, 'clf__kernel': 'poly', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': StandardScaler()}\n",
      "0.6520763187429854 {'clf__C': 10, 'clf__kernel': 'sigmoid', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.6576879910213244 {'clf__C': 10, 'clf__kernel': 'sigmoid', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': StandardScaler()}\n",
      "0.6520763187429854 {'clf__C': 10, 'clf__kernel': 'sigmoid', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.6576879910213244 {'clf__C': 10, 'clf__kernel': 'sigmoid', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': StandardScaler()}\n",
      "0.6487093153759821 {'clf__C': 10, 'clf__kernel': 'sigmoid', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.6509539842873177 {'clf__C': 10, 'clf__kernel': 'sigmoid', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': StandardScaler()}\n",
      "0.8181818181818182 {'clf__C': 50, 'clf__kernel': 'rbf', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.7934904601571269 {'clf__C': 50, 'clf__kernel': 'rbf', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': StandardScaler()}\n",
      "0.8226711560044894 {'clf__C': 50, 'clf__kernel': 'rbf', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.7934904601571269 {'clf__C': 50, 'clf__kernel': 'rbf', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': StandardScaler()}\n",
      "0.8215488215488215 {'clf__C': 50, 'clf__kernel': 'rbf', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.7934904601571269 {'clf__C': 50, 'clf__kernel': 'rbf', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': StandardScaler()}\n",
      "0.7867564534231201 {'clf__C': 50, 'clf__kernel': 'linear', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.7856341189674523 {'clf__C': 50, 'clf__kernel': 'linear', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': StandardScaler()}\n",
      "0.7867564534231201 {'clf__C': 50, 'clf__kernel': 'linear', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.7867564534231201 {'clf__C': 50, 'clf__kernel': 'linear', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': StandardScaler()}\n",
      "0.7867564534231201 {'clf__C': 50, 'clf__kernel': 'linear', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.7867564534231201 {'clf__C': 50, 'clf__kernel': 'linear', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': StandardScaler()}\n",
      "0.8125701459034792 {'clf__C': 50, 'clf__kernel': 'poly', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.7979797979797979 {'clf__C': 50, 'clf__kernel': 'poly', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': StandardScaler()}\n",
      "0.8136924803591471 {'clf__C': 50, 'clf__kernel': 'poly', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.8002244668911335 {'clf__C': 50, 'clf__kernel': 'poly', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': StandardScaler()}\n",
      "0.8215488215488215 {'clf__C': 50, 'clf__kernel': 'poly', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.8069584736251403 {'clf__C': 50, 'clf__kernel': 'poly', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': StandardScaler()}\n",
      "0.6599326599326599 {'clf__C': 50, 'clf__kernel': 'sigmoid', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.628507295173962 {'clf__C': 50, 'clf__kernel': 'sigmoid', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': StandardScaler()}\n",
      "0.6576879910213244 {'clf__C': 50, 'clf__kernel': 'sigmoid', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.6329966329966329 {'clf__C': 50, 'clf__kernel': 'sigmoid', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': StandardScaler()}\n",
      "0.6588103254769923 {'clf__C': 50, 'clf__kernel': 'sigmoid', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.6868686868686869 {'clf__C': 50, 'clf__kernel': 'sigmoid', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': StandardScaler()}\n",
      "0.8204264870931538 {'clf__C': 100, 'clf__kernel': 'rbf', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.7878787878787877 {'clf__C': 100, 'clf__kernel': 'rbf', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': StandardScaler()}\n",
      "0.8193041526374859 {'clf__C': 100, 'clf__kernel': 'rbf', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.7878787878787877 {'clf__C': 100, 'clf__kernel': 'rbf', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': StandardScaler()}\n",
      "0.8249158249158249 {'clf__C': 100, 'clf__kernel': 'rbf', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.7856341189674523 {'clf__C': 100, 'clf__kernel': 'rbf', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': StandardScaler()}\n",
      "0.7856341189674523 {'clf__C': 100, 'clf__kernel': 'linear', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.7856341189674523 {'clf__C': 100, 'clf__kernel': 'linear', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': StandardScaler()}\n",
      "0.7867564534231201 {'clf__C': 100, 'clf__kernel': 'linear', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.7867564534231201 {'clf__C': 100, 'clf__kernel': 'linear', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': StandardScaler()}\n",
      "0.7867564534231201 {'clf__C': 100, 'clf__kernel': 'linear', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.7867564534231201 {'clf__C': 100, 'clf__kernel': 'linear', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': StandardScaler()}\n",
      "0.8114478114478114 {'clf__C': 100, 'clf__kernel': 'poly', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.7946127946127947 {'clf__C': 100, 'clf__kernel': 'poly', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': StandardScaler()}\n",
      "0.8125701459034792 {'clf__C': 100, 'clf__kernel': 'poly', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.7957351290684626 {'clf__C': 100, 'clf__kernel': 'poly', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': StandardScaler()}\n",
      "0.8125701459034792 {'clf__C': 100, 'clf__kernel': 'poly', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.797979797979798 {'clf__C': 100, 'clf__kernel': 'poly', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': StandardScaler()}\n",
      "0.6565656565656566 {'clf__C': 100, 'clf__kernel': 'sigmoid', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.6273849607182941 {'clf__C': 100, 'clf__kernel': 'sigmoid', 'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': StandardScaler()}\n",
      "0.6588103254769921 {'clf__C': 100, 'clf__kernel': 'sigmoid', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.6341189674523008 {'clf__C': 100, 'clf__kernel': 'sigmoid', 'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': StandardScaler()}\n",
      "0.6632996632996633 {'clf__C': 100, 'clf__kernel': 'sigmoid', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.6846240179573512 {'clf__C': 100, 'clf__kernel': 'sigmoid', 'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': StandardScaler()}\n"
     ]
    }
   ],
   "source": [
    "for mean_score, params in zip(svc_res[\"mean_test_score\"], svc_res[\"params\"]):\n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8271604938271605"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_svc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 1,\n",
       " 'clf__kernel': 'rbf',\n",
       " 'preparation__num__imputer__strategy': 'mean',\n",
       " 'preparation__num__scaler': StandardScaler()}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_svc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8282828282828283"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, cross_val_predict(SVC(C=1.5, random_state=42), X, y, cv=StratifiedKFold(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_pipe = Pipeline([('preparation', prep_pipe),\n",
    "                     ('clf', GradientBoostingClassifier(random_state=42))])\n",
    "\n",
    "param = {'preparation__num__imputer__strategy': ['mean', 'median', 'most_frequent'],\n",
    "         'preparation__num__scaler': [MinMaxScaler(), StandardScaler()],\n",
    "         'clf__loss': ['deviance', 'exponential'],\n",
    "         'clf__learning_rate': [0.1, 0.5, 0.8],\n",
    "         'clf__n_estimators': [100, 400, 600],\n",
    "         'clf__criterion': ['friedman_mse', 'mse', 'mae'],\n",
    "         'clf__max_depth': [2, 3, 4, 5]}\n",
    "\n",
    "grid_gb = GridSearchCV(gb_pipe, param, scoring='accuracy', cv=StratifiedKFold(3))\n",
    "\n",
    "grid_gb.fit(data, y)\n",
    "\n",
    "gb_res = grid_gb.cv_results_\n",
    "\n",
    "for mean_score, params in zip(gb_res[\"mean_test_score\"], gb_res[\"params\"]):\n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8125701459034792 {'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.8136924803591471 {'preparation__num__imputer__strategy': 'mean', 'preparation__num__scaler': StandardScaler()}\n",
      "0.8080808080808081 {'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.8092031425364757 {'preparation__num__imputer__strategy': 'median', 'preparation__num__scaler': StandardScaler()}\n",
      "0.8136924803591471 {'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': MinMaxScaler()}\n",
      "0.8148148148148149 {'preparation__num__imputer__strategy': 'most_frequent', 'preparation__num__scaler': StandardScaler()}\n"
     ]
    }
   ],
   "source": [
    "gb_pipe = Pipeline([('preparation', prep_pipe),\n",
    "                     ('clf', GradientBoostingClassifier(random_state=42))])\n",
    "\n",
    "grid_gb = GridSearchCV(gb_pipe, {'preparation__num__imputer__strategy': ['mean', 'median', 'most_frequent'],\n",
    "                                 'preparation__num__scaler': [MinMaxScaler(), StandardScaler()]}, \n",
    "                      scoring='accuracy', cv=StratifiedKFold(3))\n",
    "\n",
    "grid_gb.fit(data, y)\n",
    "\n",
    "gb_res = grid_gb.cv_results_\n",
    "\n",
    "for mean_score, params in zip(gb_res[\"mean_test_score\"], gb_res[\"params\"]):\n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "             estimator=GradientBoostingClassifier(random_state=42),\n",
       "             param_grid={'criterion': ['friedman_mse', 'mae'],\n",
       "                         'learning_rate': [0.1, 0.15],\n",
       "                         'loss': ['deviance', 'exponential'],\n",
       "                         'max_depth': [6, 7], 'n_estimators': [50, 60]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pipe = Pipeline([('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "                     ('scaler', StandardScaler())])\n",
    "\n",
    "prep_pipe = ColumnTransformer([('num', num_pipe, num),\n",
    "                               ('cat', OneHotEncoder(), cat)])\n",
    "\n",
    "X = prep_pipe.fit_transform(data)\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "param = {'loss': ['deviance', 'exponential'],\n",
    "         'learning_rate': [0.1, 0.15],\n",
    "         'n_estimators': [50, 60],\n",
    "         'criterion': ['friedman_mse', 'mae'],\n",
    "         'max_depth': [6, 7]}\n",
    "\n",
    "grid_gb = GridSearchCV(gb_clf, param, scoring='accuracy', cv=StratifiedKFold(3))\n",
    "\n",
    "grid_gb.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8294051627384961,\n",
       " {'criterion': 'friedman_mse',\n",
       "  'learning_rate': 0.1,\n",
       "  'loss': 'exponential',\n",
       "  'max_depth': 6,\n",
       "  'n_estimators': 50})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_gb.best_score_, grid_gb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Fare', 0.2510068999216268),\n",
       " ('male', 0.24537990542373575),\n",
       " ('Age', 0.19215879410284592),\n",
       " ('female', 0.09762004207671861),\n",
       " (3, 0.08798793273633222),\n",
       " ('SibSp', 0.05407387738117184),\n",
       " (1, 0.030556520023000668),\n",
       " ('Parch', 0.016526233212211527),\n",
       " (2, 0.00822975357958156),\n",
       " ('S', 0.008026962752003337),\n",
       " ('C', 0.006896866042292518),\n",
       " ('Q', 0.001536212748479221)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp = grid_gb.best_estimator_.feature_importances_\n",
    "cat_enc = prep_pipe.named_transformers_[\"cat\"].categories_\n",
    "feats = num + [el for sublist in cat_enc for el in sublist]\n",
    "\n",
    "sorted(list(zip(feats, feat_imp)), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7912457912457912 {'clf': LogisticRegression()}\n",
      "0.8260381593714928 {'clf': SVC()}\n",
      "0.7721661054994389 {'clf': DecisionTreeClassifier()}\n",
      "0.8002244668911335 {'clf': RandomForestClassifier()}\n",
      "0.8148148148148149 {'clf': GradientBoostingClassifier()}\n"
     ]
    }
   ],
   "source": [
    "y = data['Survived'].values\n",
    "num = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
    "cat = ['Sex', 'Embarked']\n",
    "\n",
    "clf_pipe = Pipeline([('preparation', prep_pipe),\n",
    "                     ('clf', LogisticRegression())])\n",
    "\n",
    "grid_clf = GridSearchCV(clf_pipe, {'clf': [LogisticRegression(),\n",
    "                                           SVC(),\n",
    "                                           DecisionTreeClassifier(), \n",
    "                                           RandomForestClassifier(), \n",
    "                                           GradientBoostingClassifier()]}, \n",
    "                        scoring='accuracy', cv=StratifiedKFold(3))\n",
    "grid_clf.fit(data, y)\n",
    "\n",
    "cvres = grid_clf.cv_results_\n",
    "\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttributesSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features, num_attr=5): \n",
    "        self.num_attr = num_attr\n",
    "        self.features = features\n",
    "    def fit(self, X, y=None):\n",
    "        return self  \n",
    "    def transform(self, X):\n",
    "        idx = self.features.argsort()[-self.num_attr:]\n",
    "        return X[:,idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipe = Pipeline([('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "                     ('scaler', StandardScaler())])\n",
    "\n",
    "prep_pipe = ColumnTransformer([('num', num_pipe, num),\n",
    "                               ('cat', OneHotEncoder(), cat)])\n",
    "\n",
    "pipeline_plus = Pipeline([('preparation', prep_pipe), \n",
    "                          ('attribs_sel', AttributesSelector(feat_imp, 12))])\n",
    "\n",
    "X_imp = pipeline_plus.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(loss='exponential', max_depth=6, n_estimators=50,\n",
       "                           random_state=42)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_gb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8271604938271605"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(grid_gb.best_estimator_, X_imp, y, scoring='accuracy', cv=StratifiedKFold(3)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipe = Pipeline([('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "                     ('scaler', StandardScaler())])\n",
    "\n",
    "num = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "cat = ['Pclass', 'Sex', 'Embarked']\n",
    "\n",
    "prep_pipe = ColumnTransformer([('num', num_pipe, num),\n",
    "                               ('cat', OneHotEncoder(), cat)])\n",
    "\n",
    "X_train = prep_pipe.fit_transform(data.iloc[:,1:])\n",
    "y_train = data['Survived'].values\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "X_test = prep_pipe.transform(test.iloc[:,1:])\n",
    "\n",
    "gb_best = grid_gb.best_estimator_.fit(X_train, y_train)\n",
    "y_pred = gb_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_df = pd.DataFrame(data=list(zip(test['PassengerId'].values, y_pred)), columns=['PassengerId', 'Survived'])\n",
    "\n",
    "y_pred_df.to_csv('submission.csv', sep=',', index=False)\n",
    "\n",
    "#0.76794"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Ticket_num'] = data['Ticket'].apply(lambda x: x.split()[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Ticket_num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Leonard, Mr. Lionel</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LINE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>LINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Tornquist, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LINE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>LINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mr. William Cahoone Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LINE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>LINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mr. Alfred</td>\n",
       "      <td>male</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>LINE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>LINE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass                             Name   Sex   Age  \\\n",
       "PassengerId                                                                  \n",
       "180                 0       3              Leonard, Mr. Lionel  male  36.0   \n",
       "272                 1       3     Tornquist, Mr. William Henry  male  25.0   \n",
       "303                 0       3  Johnson, Mr. William Cahoone Jr  male  19.0   \n",
       "598                 0       3              Johnson, Mr. Alfred  male  49.0   \n",
       "\n",
       "             SibSp  Parch Ticket  Fare Cabin Embarked Ticket_num  \n",
       "PassengerId                                                       \n",
       "180              0      0   LINE   0.0   NaN        S       LINE  \n",
       "272              0      0   LINE   0.0   NaN        S       LINE  \n",
       "303              0      0   LINE   0.0   NaN        S       LINE  \n",
       "598              0      0   LINE   0.0   NaN        S       LINE  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.Ticket_num.str.contains(r'\\D')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.       , -0.0963999],\n",
       "       [-0.0963999,  1.       ]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = data.query('Ticket_num != \"LINE\"')\n",
    "np.corrcoef(temp['Ticket_num'].apply(int).values, temp['Survived'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7912457912457912 {'clf': LogisticRegression()}\n",
      "0.8260381593714928 {'clf': SVC()}\n",
      "0.7687991021324354 {'clf': DecisionTreeClassifier()}\n",
      "0.8002244668911335 {'clf': RandomForestClassifier()}\n",
      "0.8148148148148149 {'clf': GradientBoostingClassifier()}\n"
     ]
    }
   ],
   "source": [
    "y = data['Survived'].values\n",
    "num = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "cat = ['Ticket_num', 'Pclass', 'Sex', 'Embarked']\n",
    "\n",
    "clf_pipe = Pipeline([('preparation', prep_pipe),\n",
    "                     ('clf', LogisticRegression())])\n",
    "\n",
    "grid_clf = GridSearchCV(clf_pipe, {'clf': [LogisticRegression(),\n",
    "                                           SVC(),\n",
    "                                           DecisionTreeClassifier(), \n",
    "                                           RandomForestClassifier(), \n",
    "                                           GradientBoostingClassifier()]}, \n",
    "                        scoring='accuracy', cv=StratifiedKFold(3))\n",
    "grid_clf.fit(data, y)\n",
    "\n",
    "cvres = grid_clf.cv_results_\n",
    "\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "             estimator=GradientBoostingClassifier(random_state=42),\n",
       "             param_grid={'criterion': ['friedman_mse', 'mae'],\n",
       "                         'learning_rate': [0.1, 0.15],\n",
       "                         'loss': ['deviance', 'exponential'],\n",
       "                         'max_depth': [6, 7], 'n_estimators': [50, 60]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pipe = Pipeline([('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "                     ('scaler', StandardScaler())])\n",
    "\n",
    "prep_pipe = ColumnTransformer([('num', num_pipe, num),\n",
    "                               ('cat', OneHotEncoder(), cat)])\n",
    "\n",
    "X = prep_pipe.fit_transform(data)\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "param = {'loss': ['deviance', 'exponential'],\n",
    "         'learning_rate': [0.1, 0.15],\n",
    "         'n_estimators': [50, 60],\n",
    "         'criterion': ['friedman_mse', 'mae'],\n",
    "         'max_depth': [6, 7]}\n",
    "\n",
    "grid_gb = GridSearchCV(gb_clf, param, scoring='accuracy', cv=StratifiedKFold(3))\n",
    "\n",
    "grid_gb.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8350168350168351,\n",
       " {'criterion': 'friedman_mse',\n",
       "  'learning_rate': 0.1,\n",
       "  'loss': 'deviance',\n",
       "  'max_depth': 7,\n",
       "  'n_estimators': 60})"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_gb.best_score_, grid_gb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "titles = data['Name'].str.extract(r'(\\w+)\\.')[0].value_counts().index\n",
    "\n",
    "class FeautersAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, title_num=6, age_bucket=True): \n",
    "        self.title_num = title_num\n",
    "        self.age_bucket = age_bucket\n",
    "    def fit(self, X, y=None):\n",
    "        return self  \n",
    "    def transform(self, X):\n",
    "        for t in titles[:self.title_num]:\n",
    "            X[t] = X['Name'].str.contains(t).astype(int)\n",
    "                                \n",
    "        X['Siblings'] = X['SibSp'] + X['Parch']\n",
    "        X['Alone'] = X['Siblings'] == 0\n",
    "        X['Alone'] = X['Alone'].astype(int)\n",
    "        \n",
    "               \n",
    "        if self.age_bucket:\n",
    "            X['Age_groups'] = pd.cut(X['Age'], 6, labels=['a', 'b', 'c', 'd', 'e', 'f'])\n",
    "            X.drop('Age', axis=1, inplace=True)\n",
    "                      \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', index_col='PassengerId')\n",
    "age_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "train['Age'] = age_imputer.fit_transform(train['Age'].values.reshape(-1, 1))\n",
    "\n",
    "n = 6\n",
    "feat_plus = FeautersAdder(n)\n",
    "train_plus = feat_plus.fit_transform(train)\n",
    "\n",
    "num = ['SibSp', 'Parch', 'Fare', 'Siblings']\n",
    "cat = ['Pclass', 'Sex', 'Embarked', 'Age_groups']\n",
    "plus = ['Alone'] + list(titles[:n])\n",
    "\n",
    "num_pipe = Pipeline([('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "                     ('scaler', StandardScaler())])\n",
    "\n",
    "cat_pipe = Pipeline([('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "                     ('encoder', OneHotEncoder())])\n",
    "\n",
    "prep_pipe = ColumnTransformer([('num', num_pipe, num),\n",
    "                               ('cat', cat_pipe, cat)])\n",
    "\n",
    "X_train = prep_pipe.fit_transform(train_plus)\n",
    "\n",
    "X_train = np.concatenate((X_train, train_plus[plus].values), axis=1)\n",
    "y_train = train['Survived'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.840628507295174,\n",
       " {'criterion': 'friedman_mse',\n",
       "  'learning_rate': 0.15,\n",
       "  'loss': 'exponential',\n",
       "  'max_depth': 5,\n",
       "  'n_estimators': 45})"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_clf = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "param = {'loss': ['deviance', 'exponential'],\n",
    "         'learning_rate': [0.15, 0.16],\n",
    "         'n_estimators': [45, 50],\n",
    "         'criterion': ['friedman_mse', 'mae'],\n",
    "         'max_depth': [4, 5]}\n",
    "\n",
    "grid_gb = GridSearchCV(gb_clf, param, scoring='accuracy', cv=StratifiedKFold(3))\n",
    "\n",
    "grid_gb.fit(X_train, y_train)\n",
    "\n",
    "grid_gb.best_score_, grid_gb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('male', 0.2744793715096805),\n",
       " ('Fare', 0.22695901707477653),\n",
       " ('Age', 0.15554831046929404),\n",
       " (3, 0.09207685049532069),\n",
       " ('female', 0.07818353767858076),\n",
       " ('Siblings', 0.07748341930609977),\n",
       " ('Master', 0.03709632102360079),\n",
       " (2, 0.012505848998354064),\n",
       " ('Mr', 0.008968478000781413),\n",
       " ('S', 0.0070159641928528825),\n",
       " (1, 0.007015086886699328),\n",
       " ('Parch', 0.0051631011600292475),\n",
       " ('C', 0.004500368664798324),\n",
       " ('Mrs', 0.004485570855296558),\n",
       " ('Miss', 0.003401407781481849),\n",
       " ('Q', 0.002827489661327626),\n",
       " ('Alone', 0.0018910049064723806),\n",
       " ('Rev', 0.0003386198906634104),\n",
       " ('Dr', 6.023144389004892e-05)]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp = grid_gb.best_estimator_.feature_importances_\n",
    "cat_enc = prep_pipe.named_transformers_[\"cat\"]['encoder'].categories_\n",
    "feats = num + [el for sublist in cat_enc for el in sublist] + plus\n",
    "\n",
    "sorted(list(zip(feats, feat_imp)), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8316498316498316"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atr_sel = AttributesSelector(feat_imp, 15)\n",
    "X_imp = atr_sel.fit_transform(X_train)\n",
    "\n",
    "cross_val_score(grid_gb.best_estimator_, X_imp, y, scoring='accuracy', cv=StratifiedKFold(3)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.840628507295174"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv', index_col='PassengerId')\n",
    "age_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "train['Age'] = age_imputer.fit_transform(train['Age'].values.reshape(-1, 1))\n",
    "\n",
    "n = 6\n",
    "feat_plus = FeautersAdder(n, False)\n",
    "train_plus = feat_plus.fit_transform(train)\n",
    "\n",
    "num = ['Age', 'Parch', 'Fare', 'Siblings']\n",
    "cat = ['Pclass', 'Sex', 'Embarked']\n",
    "plus = ['Alone'] + list(titles[:n])\n",
    "\n",
    "num_pipe = Pipeline([('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "                     ('scaler', StandardScaler())])\n",
    "\n",
    "cat_pipe = Pipeline([('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "                     ('encoder', OneHotEncoder())])\n",
    "\n",
    "prep_pipe = ColumnTransformer([('num', num_pipe, num),\n",
    "                               ('cat', cat_pipe, cat)])\n",
    "\n",
    "X_train = prep_pipe.fit_transform(train_plus.iloc[:,1:])\n",
    "\n",
    "X_train = np.concatenate((X_train, train_plus[plus].values), axis=1)\n",
    "y_train = train['Survived'].values\n",
    "\n",
    "cross_val_score(grid_gb.best_estimator_, X_train, y_train, scoring='accuracy', cv=StratifiedKFold(3)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv', index_col='PassengerId')\n",
    "test['Age'] = age_imputer.transform(test['Age'].values.reshape(-1, 1))\n",
    "\n",
    "test_plus = feat_plus.transform(test)\n",
    "\n",
    "X_test = prep_pipe.transform(test_plus)\n",
    "\n",
    "X_test = np.concatenate((X_test, test_plus[plus].values), axis=1)\n",
    "\n",
    "gb_best = grid_gb.best_estimator_.fit(X_train, y_train)\n",
    "y_pred = gb_best.predict(X_test)\n",
    "\n",
    "y_pred_df = pd.DataFrame(data=list(zip(test.index, y_pred)), columns=['PassengerId', 'Survived'])\n",
    "y_pred_df.to_csv('submission.csv', sep=',', index=False)\n",
    "\n",
    "#0.76076"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8148148148148149"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv', index_col='PassengerId')\n",
    "age_imputer = SimpleImputer(strategy=\"median\")\n",
    "train['Age'] = age_imputer.fit_transform(train['Age'].values.reshape(-1, 1))\n",
    "\n",
    "n = len(titles)\n",
    "feat_plus = FeautersAdder(n, True)\n",
    "train_plus = feat_plus.fit_transform(train)\n",
    "\n",
    "num = ['Fare', 'Parch', 'Siblings']\n",
    "cat = ['Pclass', 'Sex', 'Age_groups']\n",
    "plus = ['Alone'] + list(titles[:n])\n",
    "\n",
    "num_pipe = Pipeline([('imputer', SimpleImputer(strategy=\"median\")),\n",
    "                     ('scaler', StandardScaler())])\n",
    "\n",
    "cat_pipe = Pipeline([('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "                     ('encoder', OneHotEncoder())])\n",
    "\n",
    "prep_pipe = ColumnTransformer([('num', num_pipe, num),\n",
    "                               ('cat', cat_pipe, cat)])\n",
    "\n",
    "X_train = prep_pipe.fit_transform(train_plus.iloc[:,1:])\n",
    "\n",
    "X_train = np.concatenate((X_train, train_plus[plus].values), axis=1)\n",
    "y_train = train['Survived'].values\n",
    "\n",
    "cross_val_score(grid_gb.best_estimator_, X_train, y_train, scoring='accuracy', cv=StratifiedKFold(3)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv', index_col='PassengerId')\n",
    "test['Age'] = age_imputer.transform(test['Age'].values.reshape(-1, 1))\n",
    "test_plus = feat_plus.transform(test)\n",
    "\n",
    "X_test = prep_pipe.transform(test_plus)\n",
    "\n",
    "X_test = np.concatenate((X_test, test_plus[plus].values), axis=1)\n",
    "\n",
    "gb_best = grid_gb.best_estimator_.fit(X_train, y_train)\n",
    "y_pred = gb_best.predict(X_test)\n",
    "\n",
    "y_pred_df = pd.DataFrame(data=list(zip(test.index, y_pred)), columns=['PassengerId', 'Survived'])\n",
    "y_pred_df.to_csv('submission.csv', sep=',', index=False)\n",
    "\n",
    "#0.75358"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8327721661054994"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv', index_col='PassengerId')\n",
    "age_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "train['Age'] = age_imputer.fit_transform(train['Age'].values.reshape(-1, 1))\n",
    "\n",
    "n = 3\n",
    "feat_plus = FeautersAdder(n, False)\n",
    "train_plus = feat_plus.fit_transform(train)\n",
    "\n",
    "num = ['Age', 'Parch', 'Fare', 'Siblings']\n",
    "cat = ['Pclass', 'Sex', 'Embarked']\n",
    "plus = ['Alone'] + list(titles[:n])\n",
    "\n",
    "num_pipe = Pipeline([('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "                     ('scaler', StandardScaler())])\n",
    "\n",
    "cat_pipe = Pipeline([('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "                     ('encoder', OneHotEncoder())])\n",
    "\n",
    "prep_pipe = ColumnTransformer([('num', num_pipe, num),\n",
    "                               ('cat', cat_pipe, cat)])\n",
    "\n",
    "X_train = prep_pipe.fit_transform(train_plus.iloc[:,1:])\n",
    "\n",
    "X_train = np.concatenate((X_train, train_plus[plus].values), axis=1)\n",
    "y_train = train['Survived'].values\n",
    "\n",
    "cross_val_score(grid_gb.best_estimator_, X_train, y_train, scoring='accuracy', cv=StratifiedKFold(3)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv', index_col='PassengerId')\n",
    "test['Age'] = age_imputer.transform(test['Age'].values.reshape(-1, 1))\n",
    "test_plus = feat_plus.transform(test)\n",
    "\n",
    "X_test = prep_pipe.transform(test_plus)\n",
    "\n",
    "X_test = np.concatenate((X_test, test_plus[plus].values), axis=1)\n",
    "\n",
    "gb_best = grid_gb.best_estimator_.fit(X_train, y_train)\n",
    "y_pred = gb_best.predict(X_test)\n",
    "\n",
    "y_pred_df = pd.DataFrame(data=list(zip(test.index, y_pred)), columns=['PassengerId', 'Survived'])\n",
    "y_pred_df.to_csv('submission.csv', sep=',', index=False)\n",
    "\n",
    "#0.77033 - best score of gb (worse than SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8002244668911335, {'criterion': 'entropy', 'n_estimators': 50})"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param = {'n_estimators': [40, 50],\n",
    "         'criterion': [\"gini\", \"entropy\"]}\n",
    "\n",
    "rnd = GridSearchCV(rnd, param, scoring='accuracy', cv=StratifiedKFold(3))\n",
    "\n",
    "rnd.fit(X_train, y_train)\n",
    "\n",
    "rnd.best_score_, rnd.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv', index_col='PassengerId')\n",
    "test['Age'] = age_imputer.transform(test['Age'].values.reshape(-1, 1))\n",
    "test_plus = feat_plus.transform(test)\n",
    "\n",
    "X_test = prep_pipe.transform(test_plus)\n",
    "\n",
    "X_test = np.concatenate((X_test, test_plus[plus].values), axis=1)\n",
    "\n",
    "rnd_best = rnd.best_estimator_.fit(X_train, y_train)\n",
    "y_pred = rnd_best.predict(X_test)\n",
    "\n",
    "y_pred_df = pd.DataFrame(data=list(zip(test.index, y_pred)), columns=['PassengerId', 'Survived'])\n",
    "y_pred_df.to_csv('submission.csv', sep=',', index=False)\n",
    "\n",
    "#0.76555"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8383838383838383"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv', index_col='PassengerId')\n",
    "age_imputer = SimpleImputer(strategy=\"mean\")\n",
    "train['Age'] = age_imputer.fit_transform(train['Age'].values.reshape(-1, 1))\n",
    "\n",
    "n = 6\n",
    "feat_plus = FeautersAdder(n)\n",
    "train_plus = feat_plus.fit_transform(train)\n",
    "\n",
    "num = ['SibSp', 'Parch', 'Fare', 'Siblings']\n",
    "cat = ['Pclass', 'Sex', 'Embarked', 'Age_groups']\n",
    "plus = ['Alone'] + list(titles[:n])\n",
    "\n",
    "num_pipe = Pipeline([('imputer', SimpleImputer(strategy=\"mean\")),\n",
    "                     ('scaler', StandardScaler())])\n",
    "\n",
    "cat_pipe = Pipeline([('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "                     ('encoder', OneHotEncoder())])\n",
    "\n",
    "prep_pipe = ColumnTransformer([('num', num_pipe, num),\n",
    "                               ('cat', cat_pipe, cat)])\n",
    "\n",
    "X_train = prep_pipe.fit_transform(train_plus.iloc[:,1:])\n",
    "\n",
    "X_train = np.concatenate((X_train, train_plus[plus].values), axis=1)\n",
    "y_train = train['Survived'].values\n",
    "\n",
    "cross_val_score(SVC(C=1.5, random_state=42), X_train, y_train, scoring='accuracy', cv=StratifiedKFold(3)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv', index_col='PassengerId')\n",
    "test['Age'] = age_imputer.transform(test['Age'].values.reshape(-1, 1))\n",
    "test_plus = feat_plus.transform(test)\n",
    "\n",
    "X_test = prep_pipe.transform(test_plus)\n",
    "\n",
    "X_test = np.concatenate((X_test, test_plus[plus].values), axis=1)\n",
    "\n",
    "svc_best = SVC(C=1.5, random_state=42).fit(X_train, y_train)\n",
    "y_pred = svc_best.predict(X_test)\n",
    "\n",
    "y_pred_df = pd.DataFrame(data=list(zip(test.index, y_pred)), columns=['PassengerId', 'Survived'])\n",
    "y_pred_df.to_csv('submission.csv', sep=',', index=False)\n",
    "\n",
    "#0.78229 - the best score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8297908077569094"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv', index_col='PassengerId')\n",
    "age_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "train['Age'] = age_imputer.fit_transform(train['Age'].values.reshape(-1, 1))\n",
    "\n",
    "train['Ticket_num'] = train['Ticket'].apply(lambda x: x.split()[-1])\n",
    "train = train.query('Ticket_num != \"LINE\"')\n",
    "train['Ticket_num'] = train['Ticket_num'].apply(int)\n",
    "\n",
    "\n",
    "n = 6\n",
    "feat_plus = FeautersAdder(n, False)\n",
    "train_plus = feat_plus.fit_transform(train)\n",
    "\n",
    "num = ['Age', 'Parch', 'Fare', 'Siblings', 'Ticket_num']\n",
    "cat = ['Pclass', 'Sex', 'Embarked']\n",
    "plus = ['Alone'] + list(titles[:n])\n",
    "\n",
    "num_pipe = Pipeline([('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "                     ('scaler', StandardScaler())])\n",
    "\n",
    "cat_pipe = Pipeline([('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "                     ('encoder', OneHotEncoder())])\n",
    "\n",
    "prep_pipe = ColumnTransformer([('num', num_pipe, num),\n",
    "                               ('cat', cat_pipe, cat)], sparse_threshold=0.001)\n",
    "\n",
    "X_train = prep_pipe.fit_transform(train_plus.iloc[:,1:])\n",
    "\n",
    "X_train = np.concatenate((X_train, train_plus[plus].values), axis=1)\n",
    "y_train = train['Survived'].values\n",
    "\n",
    "cross_val_score(grid_gb.best_estimator_, X_train, y_train, scoring='accuracy', cv=StratifiedKFold(3)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8354176210108414"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv', index_col='PassengerId')\n",
    "age_imputer = SimpleImputer(strategy=\"mean\")\n",
    "train['Age'] = age_imputer.fit_transform(train['Age'].values.reshape(-1, 1))\n",
    "\n",
    "train['Ticket_num'] = train['Ticket'].apply(lambda x: x.split()[-1])\n",
    "train = train.query('Ticket_num != \"LINE\"')\n",
    "train['Ticket_num'] = train['Ticket_num'].apply(int)\n",
    "\n",
    "n = 10\n",
    "feat_plus = FeautersAdder(n)\n",
    "train_plus = feat_plus.fit_transform(train)\n",
    "\n",
    "num = ['SibSp', 'Parch', 'Fare', 'Siblings', 'Ticket_num']\n",
    "cat = ['Pclass', 'Sex', 'Embarked', 'Age_groups']\n",
    "plus = ['Alone'] + list(titles[:n])\n",
    "\n",
    "num_pipe = Pipeline([('imputer', SimpleImputer(strategy=\"mean\")),\n",
    "                     ('scaler', StandardScaler())])\n",
    "\n",
    "cat_pipe = Pipeline([('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "                     ('encoder', OneHotEncoder())])\n",
    "\n",
    "prep_pipe = ColumnTransformer([('num', num_pipe, num),\n",
    "                               ('cat', cat_pipe, cat)], sparse_threshold=0.001)\n",
    "\n",
    "X_train = prep_pipe.fit_transform(train_plus.iloc[:,1:])\n",
    "\n",
    "X_train = np.concatenate((X_train, train_plus[plus].values), axis=1)\n",
    "y_train = train['Survived'].values\n",
    "\n",
    "cross_val_score(SVC(C=2, random_state=42), X_train, y_train, scoring='accuracy', cv=StratifiedKFold(3)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv', index_col='PassengerId')\n",
    "test['Age'] = age_imputer.transform(test['Age'].values.reshape(-1, 1))\n",
    "\n",
    "test['Ticket_num'] = test['Ticket'].apply(lambda x: int(x.split()[-1]))\n",
    "\n",
    "test_plus = feat_plus.transform(test)\n",
    "\n",
    "\n",
    "X_test = prep_pipe.transform(test_plus)\n",
    "\n",
    "X_test = np.concatenate((X_test, test_plus[plus].values), axis=1)\n",
    "\n",
    "svc_best = SVC(C=2, random_state=42).fit(X_train, y_train)\n",
    "y_pred = svc_best.predict(X_test)\n",
    "\n",
    "y_pred_df = pd.DataFrame(data=list(zip(test.index, y_pred)), columns=['PassengerId', 'Survived'])\n",
    "y_pred_df.to_csv('submission.csv', sep=',', index=False)\n",
    "\n",
    "#0.76794 - worse than previous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ИТОГО - лучшая модель и комбинация признаков:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучше всего на валидации себя показала модель SVC с параметром регуляризации 1,5 и ядром rbf. Были использованы следующие признаки:\n",
    "- числовые оригинальные из датасета: количество родственников, количество родителей/детей, стоимость билета\n",
    "- числовые дополнительные: общее количество близких \n",
    "- категориальные оригинальные: класс билета, пол пассажира, порт посадки\n",
    "- категориальные дополнительные: возрастная группа, путешествие в одиночку или нет, статус пассажира в его имени (мистер, миссис, доктор и проч.)\n",
    "\n",
    "Числовые данные были отшкалированы с использованием StandardScaler, пропуски заполнены средним, категориальные пропуски - модой, переведены в OneHot кодировку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "data = pd.read_csv('train.csv', index_col='PassengerId')\n",
    "titles = data['Name'].str.extract(r'(\\w+)\\.')[0].value_counts().index\n",
    "\n",
    "class FeautersAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, title_num=6, age_bucket=True): \n",
    "        self.title_num = title_num\n",
    "        self.age_bucket = age_bucket\n",
    "    def fit(self, X, y=None):\n",
    "        return self  \n",
    "    def transform(self, X):\n",
    "        for t in titles[:self.title_num]:\n",
    "            X[t] = X['Name'].str.contains(t).astype(int)\n",
    "                                \n",
    "        X['Siblings'] = X['SibSp'] + X['Parch']\n",
    "        X['Alone'] = X['Siblings'] == 0\n",
    "        X['Alone'] = X['Alone'].astype(int)\n",
    "        \n",
    "               \n",
    "        if self.age_bucket:\n",
    "            X['Age_groups'] = pd.cut(X['Age'], 6, labels=['a', 'b', 'c', 'd', 'e', 'f'])\n",
    "            X.drop('Age', axis=1, inplace=True)\n",
    "                      \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8383838383838383\n",
      "Precision 0.8228163000092824\n",
      "Recall 0.7397660818713451\n",
      "F1 0.7784908851960042\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv', index_col='PassengerId')\n",
    "age_imputer = SimpleImputer(strategy=\"mean\")\n",
    "train['Age'] = age_imputer.fit_transform(train['Age'].values.reshape(-1, 1))\n",
    "\n",
    "n = 6\n",
    "feat_plus = FeautersAdder(n)\n",
    "train_plus = feat_plus.fit_transform(train)\n",
    "\n",
    "num = ['SibSp', 'Parch', 'Fare', 'Siblings']\n",
    "cat = ['Pclass', 'Sex', 'Embarked', 'Age_groups']\n",
    "plus = ['Alone'] + list(titles[:n])\n",
    "\n",
    "num_pipe = Pipeline([('imputer', SimpleImputer(strategy=\"mean\")),\n",
    "                     ('scaler', StandardScaler())])\n",
    "\n",
    "cat_pipe = Pipeline([('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "                     ('encoder', OneHotEncoder())])\n",
    "\n",
    "prep_pipe = ColumnTransformer([('num', num_pipe, num),\n",
    "                               ('cat', cat_pipe, cat)])\n",
    "\n",
    "X_train = prep_pipe.fit_transform(train_plus.iloc[:,1:])\n",
    "\n",
    "X_train = np.concatenate((X_train, train_plus[plus].values), axis=1)\n",
    "y_train = train['Survived'].values\n",
    "\n",
    "print('Accuracy', cross_val_score(SVC(C=1.5, random_state=42), X_train, y_train, scoring='accuracy', cv=StratifiedKFold(3)).mean())\n",
    "print('Precision', cross_val_score(SVC(C=1.5, random_state=42), X_train, y_train, scoring='precision', cv=StratifiedKFold(3)).mean())\n",
    "print('Recall', cross_val_score(SVC(C=1.5, random_state=42), X_train, y_train, scoring='recall', cv=StratifiedKFold(3)).mean())\n",
    "print('F1', cross_val_score(SVC(C=1.5, random_state=42), X_train, y_train, scoring='f1', cv=StratifiedKFold(3)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, roc_auc_score\n",
    "\n",
    "clf = SVC(C=1.5, random_state=42, probability=True).fit(X_train, y_train)\n",
    "prob = clf.predict_proba(X_train)[:,1]\n",
    "fpr, tpr, treshold = roc_curve(y_train, prob)\n",
    "\n",
    "plt.plot(fpr, tpr,  color='darkorange',\n",
    "         label='ROC кривая (area = %0.2f)' % roc_auc_score(y_train, prob))\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC-кривая')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Валидация и загрузка на kaggle - итоговая accuracy - 0.78229 (2797ое место на лидерборде; ниже небольшой разбор лидерборда)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv', index_col='PassengerId')\n",
    "test['Age'] = age_imputer.transform(test['Age'].values.reshape(-1, 1))\n",
    "test_plus = feat_plus.transform(test)\n",
    "\n",
    "X_test = prep_pipe.transform(test_plus)\n",
    "\n",
    "X_test = np.concatenate((X_test, test_plus[plus].values), axis=1)\n",
    "\n",
    "svc_best = SVC(C=1.5, random_state=42).fit(X_train, y_train)\n",
    "y_pred = svc_best.predict(X_test)\n",
    "\n",
    "y_pred_df = pd.DataFrame(data=list(zip(test.index, y_pred)), columns=['PassengerId', 'Survived'])\n",
    "y_pred_df.to_csv('submission.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TeamId</th>\n",
       "      <th>TeamName</th>\n",
       "      <th>SubmissionDate</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3095236</td>\n",
       "      <td>Muhi</td>\n",
       "      <td>2021-07-28 13:50:47</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6362628</td>\n",
       "      <td>takumi ForGoogleClab</td>\n",
       "      <td>2021-07-28 14:15:27</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7107359</td>\n",
       "      <td>Rziting</td>\n",
       "      <td>2021-07-30 09:45:11</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7159999</td>\n",
       "      <td>Goenks</td>\n",
       "      <td>2021-07-30 05:31:52</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7146643</td>\n",
       "      <td>Zalik</td>\n",
       "      <td>2021-07-30 10:00:34</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TeamId              TeamName       SubmissionDate  Score\n",
       "0  3095236                  Muhi  2021-07-28 13:50:47    1.0\n",
       "1  6362628  takumi ForGoogleClab  2021-07-28 14:15:27    1.0\n",
       "2  7107359               Rziting  2021-07-30 09:45:11    1.0\n",
       "3  7159999                Goenks  2021-07-30 05:31:52    1.0\n",
       "4  7146643                 Zalik  2021-07-30 10:00:34    1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('titanic-publicleaderboard.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['score_groups'] = pd.cut(df.Score, (-1, 0.5, 0.7, 0.8, 0.9, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score_groups\n",
       "(-1.0, 0.5]      210\n",
       "(0.5, 0.7]       965\n",
       "(0.7, 0.8]     48642\n",
       "(0.8, 0.9]       300\n",
       "(0.9, 1.0]       168\n",
       "Name: TeamName, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('score_groups').TeamName.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9976"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query('Score != 1').Score.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.query('Score == 1.0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_most = df.query('Score >= 0.7 & Score <= 0.8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-ab9936652061>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_most['score_groups'] = pd.cut(df_most.Score, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "score_groups\n",
       "(0.701, 0.721]      289\n",
       "(0.721, 0.74]       368\n",
       "(0.74, 0.76]       1085\n",
       "(0.76, 0.779]     43874\n",
       "(0.779, 0.799]     3026\n",
       "Name: TeamName, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_most['score_groups'] = pd.cut(df_most.Score, 5)\n",
    "df_most.groupby('score_groups').TeamName.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
